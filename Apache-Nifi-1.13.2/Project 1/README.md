# Project Overview: Kazu_Fashion
The Kazu_Fashion project involves handling a wide range of product data, including details such as product_id, product_name, category, price, stock_quantity, region, monthly_revenue, address, cities_provinces, quarter, year, and rank. The business operates in several provinces of Vietnam, with specific focus on key regions such as the Red River Delta, Northern Midlands and Mountain Areas, Central Highlands, and others.

The aim of the project is to process this data automatically through a robust data pipeline designed with Apache NiFi. By utilizing NiFiâ€™s processors, data is collected from different sources, cleaned, transformed, and then stored in a structured format in a database for further analysis. This helps the business track product performance, assess revenue generation, and understand market trends based on product sales across various regions.

Key Components of the Workflow
Data Collection: The initial data source could be CSV files containing the product information. These files may come from various internal or external sources, such as the sales department, inventory systems, or spreadsheets. The data includes essential fields like product names, prices, quantities, revenue, and more.

Data Ingestion: The GenerateFlowFile and GetFile processors are used to simulate or fetch data from the source directories. These files contain product-related details that need to be processed and loaded into a central database for analysis.

Data Transformation: After ingesting the raw data, the UpdateAttribute processor is used to set important metadata such as timestamps, flow file names, and other custom attributes. This ensures that the flow files have the necessary context for processing.

Data Filtering and Querying: Once the data is ready, the QueryRecord processor is used to filter and query the dataset. For instance, products with a stock_quantity greater than 100 may be selected for further processing. In addition to filtering, the processor can also perform transformations like calculating average prices per item by dividing monthly_revenue by stock_quantity.

Data Conversion: The ConvertRecord processor is employed to convert the data from one format (such as CSV) into another (such as JSON) for compatibility with downstream systems like databases. This ensures that the data is in the appropriate format for storage and querying.

Data Storage: The transformed data is then sent to the PutDatabaseRecord processor, which is responsible for inserting the cleaned and formatted data into a relational database. In the case of Kazu_Fashion, the database could be MySQL, PostgreSQL, or any other relational database. The data will be inserted into tables like kazu_fashion_products, containing columns such as product_id, product_name, category, price, stock_quantity, region, and average_price_per_item.

Logging and Monitoring: Finally, the LogAttribute processor is used to log important information about the flow files, such as how many records were processed, what files were ingested, and other metrics. This helps with monitoring the health of the NiFi pipeline and troubleshooting any issues that might arise during the data processing.

Data Flow and Processing Details
The data flow starts when files containing product information are generated or placed in the specified directory. These files might contain product details such as:

product_id: A unique identifier for each product.
product_name: The name of the product being sold.
category: The product category (e.g., shoes, clothing, accessories).
price: The price of the product.
stock_quantity: The number of units available in stock.
region: The region where the product is being sold (e.g., Northern Vietnam, Southern Vietnam).
monthly_revenue: The total revenue generated by the product in the month.
address: The physical address of the store or warehouse handling the product.
cities_provinces: The specific cities or provinces where the product is available.
quarter: The quarter of the year in which the product's sales are recorded.
year: The year of the sales data.
rank: The product's rank based on its sales performance.
Through the use of NiFi processors, this raw data is filtered, cleaned, and transformed into a format that is suitable for storage. For example, calculations such as average_price_per_item are derived using the formula (monthly_revenue / stock_quantity) to give insights into product pricing strategies.

Data Storage in the Database
After the data is processed and transformed, it is stored in a relational database for long-term analysis. The database schema could look like this:

Table Name: kazu_fashion_products
Columns:
product_id (VARCHAR)
product_name (VARCHAR)
category (VARCHAR)
price (INT)
stock_quantity (INT)
region (VARCHAR)
average_price_per_item (DECIMAL)
monthly_revenue (BIGINT)
The PutDatabaseRecord processor inserts the cleaned and transformed data into the database, ensuring that the data is stored in a structured and easily accessible format for business intelligence tools or reporting systems.

Conclusion and Business Insights
By automating the data processing pipeline with Apache NiFi, the Kazu_Fashion project helps ensure that all product-related data is clean, structured, and ready for analysis. This automation eliminates manual data entry and minimizes errors. Additionally, the ability to query and filter data ensures that only relevant and high-quality data is stored in the database.

This pipeline can also support the business in making data-driven decisions, such as:

Analyzing product performance across different regions and provinces in Vietnam.
Identifying high-demand products based on their stock quantity and monthly revenue.
Tracking sales trends by quarter and year, helping to adjust inventory and marketing strategies accordingly.
In the long term, this system can be expanded to include more complex analytics, like predictive modeling, customer segmentation, and sales forecasting, all based on the rich, structured data collected and processed through this NiFi pipeline

![image](https://github.com/user-attachments/assets/278ea2fd-8e5c-41e9-9b20-15adf61ab068)

